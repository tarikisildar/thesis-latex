@inproceedings{Georg,
author = {Georg, Jean-Michael and Diermeyer, Frank},
year = {2019},
month = {10},
pages = {},
title = {An Adaptable and Immersive Real Time Interface for Resolving System Limitations of Automated Vehicles with Teleoperation},
doi = {10.1109/SMC.2019.8914306}
}

@INPROCEEDINGS{teleop1987,
author={Sworder, D. D. and Haaland, K. S.},
booktitle={26th IEEE Conference on Decision and Control},
title={Performance capability of a teleoperated vehicle},
year={1987},
volume={26},
number={},
pages={237-238},
keywords={Humans;Vehicle driving;Robot sensing systems;Predictive models;Control systems;Optical sensors;Differential equations;Roads;Automatic control;Optimal control},
doi={10.1109/CDC.1987.272769}}


@inproceedings{Gnatzig,
author = {Gnatzig, Sebastian and Chucholowski, Frederic and Tang, Tito and Lienkamp, Markus},
year = {2013},
month = {07},
pages = {},
title = {A System Design for Teleoperated Road Vehicles},
volume = {2},
journal = {ICINCO 2013 - Proceedings of the 10th International Conference on Informatics in Control, Automation and Robotics}
}

@article{Tang,
author = {Tang, Tito and Chucholowski, Frederic and Lienkamp, Markus},
year = {2014},
month = {02},
pages = {16-19},
title = {Teleoperated driving basics and system design},
volume = {116},
journal = {ATZ worldwide},
doi = {10.1007/s38311-014-0018-1}
}

@ARTICLE{Davis,
  author={Davis, James and Smyth, Christopher and McDowell, Kaleb},
  journal={IEEE Transactions on Robotics},
  title={The Effects of Time Lag on Driving Performance and a Possible Mitigation},
  year={2010},
  volume={26},
  number={3},
  pages={590-593},
  keywords={Displays;Control systems;Filters;Humans;Predictive models;Vehicles;Delay effects;Space exploration;Earth;Robot control;Indirect-vision driving;lag;predictive display},
  doi={10.1109/TRO.2010.2046695}
  }

@INPROCEEDINGS{Steer,
  author={Schimpe, Andreas and Diermeyer, Frank},
  booktitle={2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)},
  title={Steer with Me: A Predictive, Potential Field-Based Control Approach for Semi-Autonomous, Teleoperated Road Vehicles},
  year={2020},
  volume={},
  number={},
  pages={1-6},
  keywords={Teleoperators;Collision avoidance;Shape;Mathematical model;Predictive models;Predictive control;Trajectory},
  doi={10.1109/ITSC45102.2020.9294702}
  }

@inproceedings{Feiler2021ThePM,
  title={The Perception Modification Concept to Free the Path of An Automated Vehicle Remotely},
  author={Johannes Feiler and Frank Diermeyer},
  booktitle={International Conference on Vehicle Technology and Intelligent Transport Systems},
  year={2021},
  url={https://api.semanticscholar.org/CorpusID:235233816}
}

@misc{Brecht,
title={Evaluation of Teleoperation Concepts to solve Automated Vehicle Disengagements},
author={David Brecht and Nils Gehrke and Tobias Kerbl and Niklas Krauss and Domagoj Majstorovic and Florian Pfab and Maria-Magdalena Wolf and Frank Diermeyer},
year={2024},
eprint={2404.15030},
archivePrefix={arXiv},
primaryClass={cs.RO}
}


@Article{Kettwich,
AUTHOR = {Kettwich, Carmen and Schrank, Andreas and Oehl, Michael},
TITLE = {Teleoperation of Highly Automated Vehicles in Public Transport: User-Centered Design of a Human-Machine Interface for Remote-Operation and Its Expert Usability Evaluation},
JOURNAL = {Multimodal Technologies and Interaction},
VOLUME = {5},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {26},
URL = {https://www.mdpi.com/2414-4088/5/5/26},
ISSN = {2414-4088},
ABSTRACT = {Paving the way to future mobility, teleoperation of vehicles promises a reachable solution to effectively use the benefits of automated driving as long as fully automated vehicles (SAE 5) are not entirely feasible. Safety and reliability are assured by a human operator who remotely observes the vehicle and takes over control in cases of disturbances that exceed the vehicle automation’s skills. In order to integrate the vehicle’s automation and human remote-operation, we developed a novel user-centered human-machine interface (HMI) for teleoperation. It is tailored to the remote-operation of a highly automated shuttle (SAE 4) by a public transport control center and based on a systematic analysis of scenarios, of which detailed requirements were derived. Subsequently, a paper-pencil prototype was generated and refined until a click-dummy emerged. This click-dummy was evaluated by twelve control center professionals. The experts were presented the prototype in regular mode and were then asked to solve three scenarios with disturbances in the system. Using structured interview and questionnaire methodology, the prototype was evaluated regarding its usability, situation awareness, acceptance, and perceived workload. Results support our HMI design for teleoperation of a highly automated shuttle, especially regarding usability, acceptance, and workload. Participant ratings and comments indicated particularly high satisfaction with the interaction design to resolve disturbances and the presentation of camera images. Participants’ feedbacks provide valuable information for a refined HMI design as well as for further research.},
DOI = {10.3390/mti5050026}
}

@INPROCEEDINGS{ARGaze,
author={Doki, Kae and Funabora, Yuki and Doki, Shinji and Yano, Yoshikazu},
booktitle={2022 IEEE 20th Jubilee World Symposium on Applied Machine Intelligence and Informatics (SAMI)},
title={AR Image Presentation based on Gaze Information for Operator support in teleoperation},
year={2022},
volume={},
number={},
pages={000395-000400},
keywords={Three-dimensional displays;Head-mounted displays;Image synthesis;Resists;Hazards;Task analysis;Pupils},
doi={10.1109/SAMI54271.2022.9780732}}

@inproceedings{3DSound,
author = {Wang, MinJuan and Lyckvi, Sus Lundgren and Chen, Chenhui and Dahlstedt, Palle and Chen, Fang},
title = {Using Advisory 3D Sound Cues to Improve Drivers' Performance and Situation Awareness},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025634},
doi = {10.1145/3025453.3025634},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {2814–2825},
numpages = {12},
keywords = {in-vehicle design, drive behavior, auditory display, 3d auditory advisory traffic information system},
location = {Denver, Colorado, USA},
series = {CHI '17}
}
@article{VoiceAssistant,
title = {Exploring the benefits of conversing with a digital voice assistant during automated driving: A parametric duration model of takeover time},
journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
volume = {80},
pages = {104-126},
year = {2021},
issn = {1369-8478},
doi = {https://doi.org/10.1016/j.trf.2021.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S1369847821000668},
author = {Kirti Mahajan and David R. Large and Gary Burnett and Nagendra R. Velaga},
keywords = {Human-machine-interfaces, Voice-user interfaces (VUI), Conditional automation, SAE level 3, Passive fatigue, Driver takeover},
abstract = {Vehicle automation allows drivers to disengage from driving causing a potential decline in their alertness. One of the major challenges of highly automated vehicles is to ensure a timely (with respect to safety and situation awareness) takeover in such conditions. For this purpose, the current study investigated the role of an in-vehicle digital voice-assistant (VA) in conditionally automated vehicles, offering spoken discourse relating specifically to contextual factors, such as the traffic situation and road environment. The study involved twenty-four participants, each taking two drives (counterbalanced): with VA and without VA, in a driving simulator. Participants were required to takeover vehicle control following the issuance of a takeover request (TOR) near the end of each drive. A parametric duration model was adopted to find the key factors determining takeover time (TOT). Paired comparisons showed higher alertness and higher active workload (mean NASA-TLX rating) during automation when accompanied by the VA. Paired t-test comparison of gaze behavior prior to takeover showed significantly higher instances of checking traffic signal, roadside objects, and the roadway during the drive with VA, indicating higher situation awareness. The parametric model indicated that the VA increased the likelihood of making a timely takeover by 39%. There was also some evidence suggesting that male drivers are likely to resume control 1.21 times earlier than female drivers. The study findings highlight the benefits of adopting a digital voice assistant to keep the drivers alert and aware about the recent traffic environment in partially automated vehicles.}
}

@article{Haptic,
author = {Brendan Corbett, Chang S. Nam and Takehiko Yamaguchi},
title = {The Effects of Haptic Feedback and Visual Distraction on Pointing Task Performance},
journal = {International Journal of Human–Computer Interaction},
volume = {32},
number = {2},
pages = {89--102},
year = {2016},
publisher = {Taylor \& Francis},
doi = {10.1080/10447318.2015.1094914},}

@misc{FernrideSystem,
    author = {{Fernride}},
    title = {Operator workstation for commercial use},
    howpublished = {\url{https://www.fernride.com/system}},
    note = {Accessed: 2024-06-01}
}

@misc{Zoox,
author = {Zoox Inc.},
title = {How Zoox Uses Computer Vision To Advance Its Self-Driving Technology
},
howpublished = {YouTube},
year = {2021},
url = {https://www.youtube.com/watch?v=BVRMh9NO9Cs},
note = {Accessed: 2024-06-01}
}

@Article{Florea,
AUTHOR = {Florea, Horatiu and Petrovai, Andra and Giosan, Ion and Oniga, Florin and Varga, Robert and Nedevschi, Sergiu},
TITLE = {Enhanced Perception for Autonomous Driving Using Semantic and Geometric Data Fusion},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {13},
ARTICLE-NUMBER = {5061},
URL = {https://www.mdpi.com/1424-8220/22/13/5061},
PubMedID = {35808555},
ISSN = {1424-8220},
ABSTRACT = {Environment perception remains one of the key tasks in autonomous driving for which solutions have yet to reach maturity. Multi-modal approaches benefit from the complementary physical properties specific to each sensor technology used, boosting overall performance. The added complexity brought on by data fusion processes is not trivial to solve, with design decisions heavily influencing the balance between quality and latency of the results. In this paper we present our novel real-time, 360∘ enhanced perception component based on low-level fusion between geometry provided by the LiDAR-based 3D point clouds and semantic scene information obtained from multiple RGB cameras, of multiple types. This multi-modal, multi-sensor scheme enables better range coverage, improved detection and classification quality with increased robustness. Semantic, instance and panoptic segmentations of 2D data are computed using efficient deep-learning-based algorithms, while 3D point clouds are segmented using a fast, traditional voxel-based solution. Finally, the fusion obtained through point-to-image projection yields a semantically enhanced 3D point cloud that allows enhanced perception through 3D detection refinement and 3D object classification. The planning and control systems of the vehicle receives the individual sensors’ perception together with the enhanced one, as well as the semantically enhanced 3D points. The developed perception solutions are successfully integrated onto an autonomous vehicle software stack, as part of the UP-Drive project.},
DOI = {10.3390/s22135061}
}

@inproceedings{Schimpe,
author = {Schimpe, Andreas and Feiler, Johannes and Hoffmann, Simon and Majstorovic, Domagoj and Diermeyer, Frank},
year = {2022},
month = {03},
pages = {1-6},
title = {Open Source Software for Teleoperated Driving},
doi = {10.1109/ICCVE52871.2022.9742859}
}


